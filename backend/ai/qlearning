import numpy as np
import random
import pandas as pd

class QLearningAgent:
    def __init__(self, actions, alpha=0.1, gamma=0.9, epsilon=1.0, epsilon_decay=0.995, epsilon_min=0.01):
        self.actions = actions  # Különböző akciók (pl. 'buy', 'sell', 'hold')
        self.alpha = alpha  # Tanulási sebesség
        self.gamma = gamma  # Jutalom diskontálása
        self.epsilon = epsilon  # Epsilon, a felfedezés mértéke
        self.epsilon_decay = epsilon_decay  # Epsilon csökkentése
        self.epsilon_min = epsilon_min  # Minimális epsilon érték
        self.q_table = pd.DataFrame(columns=self.actions)  # Q-táblázat

    def act(self, state):
        # Kiválasztja a legjobb akciót vagy véletlenszerűen választ
        if random.uniform(0, 1) < self.epsilon:
            return random.choice(self.actions)  # Felfedezés (véletlenszerű)
        else:
            if state not in self.q_table.index:
                self.q_table.loc[state] = [0] * len(self.actions)
            return self.q_table.loc[state].idxmax()  # Legjobb akció (maximális Q-érték alapján)

    def learn(self, state, action, reward, next_state):
        # Q-learning frissítés
        if next_state not in self.q_table.index:
            self.q_table.loc[next_state] = [0] * len(self.actions)

        old_q_value = self.q_table.loc[state, action]
        future_q_value = self.q_table.loc[next_state].max()

        # Q érték frissítése
        new_q_value = old_q_value + self.alpha * (reward + self.gamma * future_q_value - old_q_value)
        self.q_table.loc[state, action] = new_q_value

        # Epsilon csökkentése
        if self.epsilon > self.epsilon_min:
            self.epsilon *= self.epsilon_decay

# Szimulált kereskedési környezet
class TradingEnvironment:
    def __init__(self, data):
        self.data = data  # Piaci adatok
        self.current_step = 0

    def reset(self):
        self.current_step = 0
        return self.data[self.current_step]  # Kezdeti állapot

    def step(self, action):
        # Kiszámítja a jutalmat a végrehajtott akció alapján
        current_price = self.data[self.current_step]
        reward = 0

        # Akció végrehajtása
        if action == 'buy':
            reward = self.data[self.current_step + 1] - current_price  # Nyereség, ha az ár emelkedik
        elif action == 'sell':
            reward = current_price - self.data[self.current_step + 1]  # Nyereség, ha az ár csökken

        self.current_step += 1
        done = self.current_step >= len(self.data) - 1
        next_state = self.data[self.current_step]

        return next_state, reward, done
